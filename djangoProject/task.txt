
# 1. 구현 언어
# Python 3.9
# 2. 구현 내용
# 1. 사용자로부터 이미지 및 음성을 입력받아 인공지능을 통해 데이터를 분석 및 처리한다.
# 2. GAN기술 부분에서는 입력된 이미지를 새롭게 캐릭터화된 이미지로 변환한다.
# 3. 캐릭터화된 이미지를 적용한다.
# 4. 생동감있는 움직임의 아바타를 구현한다.
# 5. 결론은 가상휴먼 캐릭터 생성이라는 주제를 프로그램으로 구현한다.
# 3. 구현 방법
# 이미지 캐릭터화 및 모션화를 위한 개발방법론이다.
# 아나콘다는 머신러닝이나 데이터 분석 등에 사용하는 여러가지 패키지가
# 기본적으로 포함되어있는 파이썬 배포이다. 아나콘다기반으로 conda라는
# 환경/패키지 관리자를 통해 필요한 OpenCV 패키지를 설치하여, 딥러닝용 가상
# 환경을 구축한다. 파이썬 개발 툴인 파이참을 통해 소스 코드 편집기로 사용한다.
# 구현환경 및 버전은 다음과 같다.
# - GPU : RTX 2080(8gb), PC 스펙 관련해서 구글코랩으로 대체함
# - CUDA : 11.2
# - cuDNN : 8.1.0
# - Python : 3.9
# - Pytorch : 1.8.0
# - Torchvision : 0.9.0
# - Cuda Toolkit : 11.1
# Style Transfer을 다음 모델을 사용해서 구현한다.
# GAN (Generative Adversarial Network (NIPS 2014))을 기본으로 사용한다.
# 그 중에서 특히 PGGAN (Progressive Growing of GAN(2017))은 처음부터
# 복잡한 네트워크를 학습하지 않아 학습 난이도가 낮고 학습하는 가중치는 낮기
# 때문에 좋은학습결과를 얻을 수 있다.
# 다음은 StyleGAN (A Style-Based Generator Architecture for GAN(CVPR
# 2019))을 사용한다.
# 이후 DualStyleGAN (Exemplar-Based High-Resolution Portrait Style
# Transfer(2022))을 통해 더 나은 성능으로 업그레이드한다.
# Motion Transfer는 다음 모델을 통해 구현한다.
# TPS (Thin-Plate Spline Motion Model for Image(2022))는 사용자가 선택한
# 이미지를 아바타화 시켜 친근성을 높이고, 타인과의 교류에 부담을 낮추되
# 교류감각을 유지하고 긍정적인 소통을 유도하는데 탁월하다.
# 얼굴 정렬 부분은 Face Alignment 으로 이미지 전처리 과정으로 사용자가
# 업로드한 이미지에서 얼굴을 인식하고 정렬한다
# 이미지 캐릭터화를 위해 다음 오픈 데이터셋을 사용한다.
# 1) nvidia FFHQ (70,000건)
# 2) cartoon image (약 300건)
# 구현은 총 3단계로 진행된다.
# 첫번째는 이미지 전처리 과정으로, 원본사진 이미지가 업로드되면, 이미지가
# 캐릭터로 변환이 가능한 인물인지 인식한다.
# 만약 이미지에 인물이 포함되어 있다면 얼굴부분만을 탐지하고, alignment 을
# 수행하여 이미지 전처리 작업을 진행한다.
# 두번째는 인물사진 캐릭터화 한다. DualStyleGAN 모델을 사용하여 사용자가
# 원하는 스타일의 캐릭터로 변화시킨세번째는 TPS 모델을 활용해서 변화시킨다.
# 이미지를 움직이는 영상 으로 생성한다.